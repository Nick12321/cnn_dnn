{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OQTla_oS3O0E"
   },
   "source": [
    "# Step By Step Machine Learning \n",
    "\n",
    "In this colaboratory notebook, you learn to work with python and machine learning models. and how to step by step develop machine learning project using Python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "857zUnkM5HON"
   },
   "source": [
    "Python Packages\n",
    " learn to load and use  machine learning packages in Python.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1.  **numpy**\n",
    "\n",
    "  NumPy is a library for the Python programming language, adding support for large, **multi-dimensional arrays and matrices**, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "  \n",
    "2.  **matplotlib**\n",
    "\n",
    "  Matplotlib is a plotting library for the Python programming language and its numerical mathematics extension NumPy. \n",
    "  \n",
    "3.  **pandas**\n",
    "\n",
    "  pandas is an open source library providing high-performance, easy-to-use **data structures** and **data analysis tools** for the Python programming language.\n",
    "  \n",
    "4.  **sklearn**\n",
    "\n",
    "  Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language.\n",
    "  \n",
    "6.  **scipy**\n",
    "\n",
    "  SciPy is a free and open-source Python library used for scientific computing and technical computing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gImLytR89eol"
   },
   "source": [
    "### Import libraries\n",
    "We need to import  all the modules, functions  before using them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FbWaB53I5iMP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-jRmYuU-4ql"
   },
   "source": [
    "### Load Dataset\n",
    "\n",
    "**Iris Data**\n",
    "\n",
    "We want to use some data sets. \n",
    "We get start with the Iris dataset which usually is used to teach the fundamentals of machine learning algorithms.\n",
    "\n",
    "Data set has been used by almost every data science beginner. This data set is the machine learning practitioner’s equivalent of “Hello, World!”.\n",
    "\n",
    "Our goal is to train a machine learning model to correctly predict the flower species from the measured attributes.\n",
    "\n",
    "\n",
    "**species**:\n",
    "\n",
    "*   Iris Setosa\n",
    "*   Iris Versicolor\n",
    "*   Iris Virginica\n",
    "\n",
    "\n",
    "**Variable**\n",
    "\n",
    "Each species of flower is quantified via four numerical attributes, all measured in centimeters:\n",
    "\n",
    "*   Sepal length\n",
    "*   Sepal width\n",
    "*   Petal length\n",
    "*   Petal width\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFBfkEL5-7MJ"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/FarnooshKh/Machine-Learning/master/Data/iris.csv\"\n",
    "dataset = pd.read_csv(url,index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kl9Vc9qXpg5w"
   },
   "source": [
    "### Summarize the Dataset\n",
    "\n",
    "\n",
    "\n",
    "*   Dimensions of the dataset.\n",
    "*   Describtion of the dataset.\n",
    "\n",
    "  Statistical summary of all attributes.\n",
    "  \n",
    "*   Class Distribution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "y3LetoKjpkTc",
    "outputId": "29dc4d1d-29e2-4149-87a3-025439a62a0c"
   },
   "outputs": [],
   "source": [
    "# shape\n",
    "print(dataset.shape)\n",
    "iris_data = dataset.iloc[:,:-2]\n",
    "iris_target = dataset['target']\n",
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nzzNwsom7gRk"
   },
   "source": [
    "**Statistical Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "3qrwM_QBqd0X",
    "outputId": "c1f17b89-9b68-4e19-dc92-afdc6e498d2b"
   },
   "outputs": [],
   "source": [
    "# descriptions\n",
    "\n",
    "print(iris_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "1Q0f0Tu4KTwp",
    "outputId": "dad2e4dd-354f-4ebc-8722-ac78e806d3e0"
   },
   "outputs": [],
   "source": [
    "iris_data.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "6CNJkZ6F7vWq",
    "outputId": "9a9d6f33-c8c0-40c8-8948-b8bec28dfa45"
   },
   "outputs": [],
   "source": [
    "# class distribution\n",
    "print(dataset.groupby('class').size())\n",
    "#dataset.groupby('class').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "SdIg4KMkI57Z",
    "outputId": "09bea225-e9aa-4dc9-ebeb-5fb0a0ae6875"
   },
   "outputs": [],
   "source": [
    "# datatype\n",
    "dataset.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FB03nh89Dpuk"
   },
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "daAqVT55L08U"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "*   Univariate plots \n",
    "\n",
    "  Better understanding of each attribute.\n",
    "\n",
    "  Plots of each individual variable.\n",
    "  \n",
    "  This gives us a much clearer idea of the distribution of the input attributes. For example if variable have Gaussian distribution then we can choose algorithms that use this assumption.\n",
    "   \n",
    "*   Multivariate plots \n",
    "\n",
    "  Better understand the relationships between attributes.\n",
    "  \n",
    "  Interactions between the variables.\n",
    "  \n",
    "  Correlation between variables\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "2M1SRxU78UzJ",
    "outputId": "61051e7d-6d52-49d9-9e19-08cf60274de3"
   },
   "outputs": [],
   "source": [
    "# two different ways of plots \n",
    "#dataset.iloc[:,:-2].hist(bins=20,figsize=(9,7),grid=False)\n",
    "iris_data.plot(kind='hist', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "OaGAjb0Z8Xkm",
    "outputId": "9f7b3716-7509-4e7a-9cd5-fcf3e3ebdd4c"
   },
   "outputs": [],
   "source": [
    "iris_data.plot(kind='box', subplots=True, layout=(2,2), sharex=False, sharey=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1031
    },
    "colab_type": "code",
    "id": "2rShZy5BLlng",
    "outputId": "ced98567-c719-4db8-8373-4b395dab950f"
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "# scatter plot matrix\n",
    "scatter_matrix(iris_data)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.pairplot(dataset.drop(\"target\", axis=1), kind=\"scatter\", hue=\"class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tcjuf63LLERE"
   },
   "source": [
    "## Splitting data to training and testing sets\n",
    "\n",
    "If we use one of our labeled fruit examples in the data that we use to train the classifier, we can't also use that same irish data as a test sample to also evaluate the classifier.\n",
    "\n",
    "The machine learning Algorithm needs to work well on any input sample (Training Set), any new pieces of data that we might see in the future(Test Set).\n",
    "\n",
    "\n",
    "\n",
    "To investigate performance of our model, we need to split the data to training and testing sets(validation set). This will help us to check potential overfitting in our model training.\n",
    "\n",
    "**random_state** as the name suggests, is used for initializing the internal random number generator, which will decide the splitting of data into train and test indices in your case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fuPez5sILHne"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data, dataset['class'], test_size=0.30, random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Erm_hL66Q5pI",
    "outputId": "194a1d64-86c8-4060-afac-1676fc65e486"
   },
   "outputs": [],
   "source": [
    "print(f'train: {X_train.size}')\n",
    "print(f'test: {X_test.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5d4mmbBCRSl8"
   },
   "source": [
    "# Building classification models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXJQ0SgBRlF7"
   },
   "source": [
    "## K nearest neighbour(KNN)\n",
    "K nearest neighbour uses a distance metric like Euclidean distance to identity similarity of target data point (sample) in test or validation set to the data points (samples) in the trainign set. Then based on the user specified k, it finds the k closest points (samples) to the target data point. Afterward, it chooses the most frequent label among the k closes points (majority voting) as the class label of the target sample. The class labels can be also assigned based on weighted voting of the k closest data points to the data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "opESR8PXQ7RW",
    "outputId": "fcb8bd47-9adc-4919-f401-578f09200e09"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize our classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=13, weights='distance' )\n",
    "\n",
    "# Fitting the model with the data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "5XWwSRM6R105",
    "outputId": "4d720a8d-16a8-4ac1-d0e3-ffbbc5cb4700"
   },
   "outputs": [],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(y_pred)\n",
    "print(y_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s5wtdouySo0B"
   },
   "source": [
    "# Performance measure\n",
    "\n",
    "To assess performance of the machine learning model, we can use the following measure of the performance of the model:\n",
    "\n",
    "\n",
    "\n",
    "* **precision** is also referred to as positive predictive value (PPV)\n",
    "\n",
    "$${\\displaystyle {\\text{Precision}}=\\text{True positive rate} = {\\frac {tp}{tp+fp}}\\,}$$\n",
    "\n",
    "* **Recall** in this context is also referred to as the true positive rate or sensitivity\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$${\\displaystyle {\\text{Recall}}={\\frac {tp}{tp+fn}}\\,} $$\n",
    "\n",
    " \n",
    "\n",
    "* **specificity** True negative rate\n",
    "\n",
    "\n",
    "\n",
    "$${\\displaystyle {\\text{True negative rate}}={\\frac {tn}{tn+fp}}\\,}$$\n",
    "\n",
    "* **Accuracy**: This measure gives you a sense of performance for all the classes together as follows:\n",
    "\n",
    "$$ {\\displaystyle {\\text{Accuracy}}={\\frac {tp+tn}{tp+tn+fp+fn}}\\,}$$\n",
    "\n",
    "\n",
    "\\begin{equation*} Accuracy=\\frac{Number\\:of\\:correct\\:predictions}{(Total\\:number\\:of\\:data\\:points (samples))} \\end{equation*}\n",
    "\n",
    "$${\\displaystyle {\\text{Balanced Accuracy}}={\\frac {TPR+TNR}{2}}\\,}$$\n",
    "\n",
    "* **Confusion matrix (or error matrix)**: True and false classification of the samples in all the classes can be shown in a matrix which is called confusion (or error) matrix. The columns are usually considered as the predicted classes and rows as actual classes. Hence, the diagonal elements of the matrix will be the total number of true classifcation in each class. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "TT10jmXASEW0",
    "outputId": "afac6b84-b8fd-43af-a069-1ba524d1d207"
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"Confusion matrix of the predictions:\\n\", metrics.confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"precision\", metrics.precision_score(y_test, y_pred, average=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "colab_type": "code",
    "id": "Zjli08Uk-RhY",
    "outputId": "6f14617d-e369-4a12-a3de-ecf9926a6dd1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    " \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred, classes= dataset['class'].unique(),\n",
    "                      title='Confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "WOQA6HIJSy2f",
    "outputId": "1add9818-58da-444f-fac6-1a63c0a03c1e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_range = list(range(1,20))\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "plt.plot(k_range, scores)\n",
    "plt.xlabel('Value of k for KNN')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.title('Accuracy Scores for Values of k of k-Nearest-Neighbors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "colab_type": "code",
    "id": "UvLZ4BLOZS1x",
    "outputId": "6eecfb76-763d-432c-a3af-90762563b208"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets\n",
    "\n",
    "n_neighbors = 3\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# we only take the first two features. We could avoid this ugly\n",
    "# slicing by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])\n",
    "\n",
    "for weights in ['uniform', 'distance']:\n",
    "    # we create an instance of Neighbours Classifier and fit the data.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "\n",
    "    # Plot also the training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n",
    "                edgecolor='k', s=20)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"3-Class classification (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UrwlRkwNKUnM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "C19053109 MachineLearning_knn_iris.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
